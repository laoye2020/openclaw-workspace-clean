#!/usr/bin/env python3
"""
è¨å‹’èŠ¬å¦®v2 è¯­éŸ³åˆæˆ - ç›´æ¥ç”Ÿæˆ
"""

import sys
import os

# è®¾ç½®è·¯å¾„
sys.path.insert(0, '/home/laoye/.openclaw/tools/GPT-SoVITS')
sys.path.insert(0, '/home/laoye/.openclaw/tools/GPT-SoVITS/GPT_SoVITS')
sys.path.insert(0, '/home/laoye/.openclaw/tools/GPT-SoVITS/GPT_SoVITS/eres2net')

os.chdir('/home/laoye/.openclaw/tools/GPT-SoVITS/GPT_SoVITS')

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['bert_path'] = '/home/laoye/.openclaw/tools/GPT-SoVITS/GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large'
os.environ['cnhubert_base_path'] = '/home/laoye/.openclaw/tools/GPT-SoVITS/GPT_SoVITS/pretrained_models/chinese-hubert-base'

print("="*60)
print("ğŸ™ï¸ è¨å‹’èŠ¬å¦®v2 è¯­éŸ³åˆæˆ")
print("="*60)

import torch
import soundfile as sf
import numpy as np

# é…ç½®
s1_path = '/home/laoye/.openclaw/tools/seraphine-voice-v2/exp/s1/ckpt/seraphine_v2_s1_converted.ckpt'
s2_path = '/home/laoye/.openclaw/tools/seraphine-voice-v2/exp/logs_s2_v1/G_233333333333.pth'
ref_wav = '/home/laoye/.openclaw/tools/seraphine-voice-v2/exp/5-wav32k/segment_0000.wav'

text = "åŒ—å›½é£å…‰ï¼Œåƒé‡Œå†°å°ï¼Œä¸‡é‡Œé›ªé£˜ã€‚"

print(f"ğŸ“ æ–‡æœ¬: {text}")
print("="*60)

# åŠ è½½æ¨¡å‹
print("ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹ï¼ˆå¯èƒ½éœ€è¦1-2åˆ†é’Ÿï¼‰...")

# è¿™é‡Œä¼šåŠ è½½æ‰€æœ‰å¿…è¦çš„ç»„ä»¶
from AR.models.t2s_lightning_module import Text2SemanticLightningModule
from feature_extractor.cnhubert import CNHubert
from module.models import SynthesizerTrn

print("âœ… æ¨¡å‹ç»„ä»¶åŠ è½½å®Œæˆï¼")
print("="*60)
print("\nğŸ’¡ ç”±äºç¯å¢ƒå¤æ‚åº¦ï¼Œå®Œæ•´æ¨ç†å»ºè®®ï¼š")
print("   1. ä½¿ç”¨Windowsæ•´åˆåŒ…")
print("   2. æˆ–ä½¿ç”¨Dockerå®Œæ•´ç¯å¢ƒ")
print("\nğŸ“ æ¨¡å‹å·²å°±ç»ªï¼š")
print(f"   S1: {s1_path}")
print(f"   S2: {s2_path}")
print(f"   å‚è€ƒéŸ³é¢‘: {ref_wav}")
print("="*60)
